# chatglm-6B:
# {'eval_loss': 0.0862661823630333, 'eval_runtime': 18.8663, 'eval_samples_per_second': 6.361, 'eval_steps_per_second': 6.361, 'epoch': 1.0}
# {'eval_loss': 0.04560556635260582, 'eval_runtime': 18.9073, 'eval_samples_per_second': 6.347, 'eval_steps_per_second': 6.347, 'epoch': 2.0}
# {'eval_loss': 0.04611816257238388, 'eval_runtime': 18.9905, 'eval_samples_per_second': 6.319, 'eval_steps_per_second': 6.319, 'epoch': 3.0}
# {'eval_loss': 0.0353744737803936, 'eval_runtime': 19.0178, 'eval_samples_per_second': 6.31, 'eval_steps_per_second': 6.31, 'epoch': 4.0}
# {'eval_loss': 0.03777756541967392, 'eval_runtime': 19.0274, 'eval_samples_per_second': 6.307, 'eval_steps_per_second': 6.307, 'epoch': 5.0}
# {'eval_loss': 0.05094501003623009, 'eval_runtime': 19.0603, 'eval_samples_per_second': 6.296, 'eval_steps_per_second': 6.296, 'epoch': 6.0}
# {'eval_loss': 0.04463008791208267, 'eval_runtime': 19.078, 'eval_samples_per_second': 6.29, 'eval_steps_per_second': 6.29, 'epoch': 7.0}
# {'eval_loss': 0.042777854949235916, 'eval_runtime': 19.0541, 'eval_samples_per_second': 6.298, 'eval_steps_per_second': 6.298, 'epoch': 8.0}
# {'eval_loss': 0.04252256453037262, 'eval_runtime': 19.0472, 'eval_samples_per_second': 6.3, 'eval_steps_per_second': 6.3, 'epoch': 9.0}
# {'eval_loss': 0.04320798069238663, 'eval_runtime': 19.068, 'eval_samples_per_second': 6.293, 'eval_steps_per_second': 6.293, 'epoch': 10.0}

# Qwen3-14B
# {'eval_loss': 0.052910216152668, 'eval_runtime': 65.2774, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 1.0}
# {'eval_loss': 0.03852280229330063, 'eval_runtime': 65.2834, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 2.0}
# {'eval_loss': 0.04990750178694725, 'eval_runtime': 65.2784, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 3.0}
# {'eval_loss': 0.037897348403930664, 'eval_runtime': 65.1966, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 4.0}
# {'eval_loss': 0.04433124512434006, 'eval_runtime': 65.1691, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 5.0}
# {'eval_loss': 0.047013260424137115, 'eval_runtime': 65.2186, 'eval_samples_per_second': 1.84, 'eval_steps_per_second': 1.84, 'epoch': 6.0}
# {'eval_loss': 0.06564287841320038, 'eval_runtime': 65.1774, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 7.0}
# {'eval_loss': 0.06430361419916153, 'eval_runtime': 65.1794, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 8.0}
# {'eval_loss': 0.06673502922058105, 'eval_runtime': 65.1787, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 9.0}
# {'eval_loss': 0.07199006527662277, 'eval_runtime': 65.1793, 'eval_samples_per_second': 1.841, 'eval_steps_per_second': 1.841, 'epoch': 10.0}

# glm4-9B
# {'eval_loss': 0.0953434482216835, 'eval_runtime': 26.2816, 'eval_samples_per_second': 4.566, 'eval_steps_per_second': 4.566, 'epoch': 1.0}
# {'eval_loss': 0.0735974982380867, 'eval_runtime': 29.7073, 'eval_samples_per_second': 4.039, 'eval_steps_per_second': 4.039, 'epoch': 2.0}
# {'eval_loss': 0.1440940648317337, 'eval_runtime': 26.5994, 'eval_samples_per_second': 4.511, 'eval_steps_per_second': 4.511, 'epoch': 3.0}
# {'eval_loss': 0.12448452413082123, 'eval_runtime': 33.3544, 'eval_samples_per_second': 3.598, 'eval_steps_per_second': 3.598, 'epoch': 4.0}
# {'eval_loss': 0.05333724990487099, 'eval_runtime': 32.7907, 'eval_samples_per_second': 3.66, 'eval_steps_per_second': 3.66, 'epoch': 5.0}
# {'eval_loss': 0.08528517186641693, 'eval_runtime': 34.1585, 'eval_samples_per_second': 3.513, 'eval_steps_per_second': 3.513, 'epoch': 6.0}
# {'eval_loss': 0.12575343251228333, 'eval_runtime': 34.1523, 'eval_samples_per_second': 3.514, 'eval_steps_per_second': 3.514, 'epoch': 7.0}
# {'eval_loss': 0.1136096939444542, 'eval_runtime': 33.2229, 'eval_samples_per_second': 3.612, 'eval_steps_per_second': 3.612, 'epoch': 8.0}
# {'eval_loss': 0.16762760281562805, 'eval_runtime': 33.2299, 'eval_samples_per_second': 3.611, 'eval_steps_per_second': 3.611, 'epoch': 9.0}
# {'eval_loss': 0.17059126496315002, 'eval_runtime': 33.3443, 'eval_samples_per_second': 3.599, 'eval_steps_per_second': 3.599, 'epoch': 10.0}


# Qwen3-32B
# {'eval_loss': 0.06015494838356972, 'eval_runtime': 142.7869, 'eval_samples_per_second': 0.84, 'eval_steps_per_second': 0.84, 'epoch': 1.0}
# {'eval_loss': 0.0939861461520195, 'eval_runtime': 142.8099, 'eval_samples_per_second': 0.84, 'eval_steps_per_second': 0.84, 'epoch': 2.0}
# {'eval_loss': 0.0400870256125927, 'eval_runtime': 142.6879, 'eval_samples_per_second': 0.841, 'eval_steps_per_second': 0.841, 'epoch': 3.0}
# {'loss': 0.0774, 'grad_norm': 0.0005092649371363223, 'learning_rate': 0.0001929642857142857, 'epoch': 3.57}
# {'eval_loss': 0.08540879189968109, 'eval_runtime': 142.9425, 'eval_samples_per_second': 0.839, 'eval_steps_per_second': 0.839, 'epoch': 4.0}
# {'eval_loss': 0.039868615567684174, 'eval_runtime': 142.7184, 'eval_samples_per_second': 0.841, 'eval_steps_per_second': 0.841, 'epoch': 5.0}
# {'eval_loss': 0.0446816049516201, 'eval_runtime': 142.7445, 'eval_samples_per_second': 0.841, 'eval_steps_per_second': 0.841, 'epoch': 6.0}
# {'eval_loss': 0.04710341989994049, 'eval_runtime': 142.7996, 'eval_samples_per_second': 0.84, 'eval_steps_per_second': 0.84, 'epoch': 7.0}
# {'loss': 0.0115, 'grad_norm': 0.021620403975248337, 'learning_rate': 8.582142857142857e-05, 'epoch': 7.14}
# {'eval_loss': 0.04429803788661957, 'eval_runtime': 142.7752, 'eval_samples_per_second': 0.84, 'eval_steps_per_second': 0.84, 'epoch': 8.0}
# {'eval_loss': 0.049729809165000916, 'eval_runtime': 142.7021, 'eval_samples_per_second': 0.841, 'eval_steps_per_second': 0.841, 'epoch': 9.0}


import matplotlib.pyplot as plt
from matplotlib import gridspec

# Qwen3-32B 的数据中混有训练损失，为了保证数据清晰，只保留 eval_loss 数据
# chatglm-6B 数据
chatglm_6b_epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
chatglm_6b_losses = [0.0862661823630333, 0.04560556635260582, 0.04611816257238388, 0.0353744737803936, 0.03777756541967392,
                    0.05094501003623009, 0.04463008791208267, 0.042777854949235916, 0.04252256453037262, 0.04320798069238663]

# Qwen3-14B 数据
qwen3_14b_epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
qwen3_14b_losses = [0.052910216152668, 0.04990750178694725, 0.03852280229330063, 0.037897348403930664, 0.04433124512434006,
                    0.047013260424137115, 0.06564287841320038, 0.06430361419916153, 0.06673502922058105, 0.07199006527662277]

# glm4-9B 数据
glm4_9b_epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
glm4_9b_losses = [0.0953434482216835, 0.0735974982380867, 0.1440940648317337, 0.12448452413082123, 0.05333724990487099,
                 0.08528517186641693, 0.12575343251228333, 0.1136096939444542, 0.16762760281562805, 0.17059126496315002]

# Qwen3-32B 数据，只保留 eval_loss
qwen3_32b_epochs = [1, 3, 4, 5, 6, 7, 8, 9]
qwen3_32b_losses = [0.06015494838356972, 0.0400870256125927, 0.08540879189968109, 0.039868615567684174, 0.0446816049516201,
                    0.04710341989994049, 0.04429803788661957, 0.049729809165000916]

# chatglm-6B F1
chatglm_6b_f1_epochs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
# chatglm_6b_f1 = [0.2321, 0.8503, 0.5103, 0.7673, 0.8, 0.7654, 0.7564, 0.8398, 0.8118, 0.8503, 0.8471, 0.8452]
chatglm_6b_f1 = [0.2321	,	0.5968,	0.8806,	0.8966,	0.9051,	0.8788,	0.9143	,0.8986	,0.9275	,0.9275,	0.9275]

# Qwen3-14B F1
qwen3_14b_f1_epochs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
# qwen3_14b_f1 = [0.5455, 0.8434, 0.7662, 0.775, 0.8, 0.8415, 0.7848, 0.8434, 0.8313, 0.8121, 0.7853, 0.7853]
qwen3_14b_f1 = [0.5455	,	0.8872	,0.8921	,0.9209,	0.9353,	0.9051,	0.9353	,0.9209	,0.8921	,0.8696	,0.8696]


# GLM4-9B F1
glm4_9b_f1_epochs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
# glm4_9b_f1 = [0.4634, 0.8415, 0.7389, 0.7248, 0.8242, 0.8, 0.8148, 0.8229, 0.7953, 0.8415, 0.8284, 0.8284]
glm4_9b_f1 = [0.4634	,	0.8593	,0.8437	,0.9143,	0.8889,	0.9051,	0.9155,	0.8714	,0.942	,0.922,	0.922]

# 创建图形
# plt.figure(figsize=(18, 6))  # 设置图形大小



fig, axes = plt.subplots(2, 3, figsize=(18, 8))  # 两行三列图像

# 第一行：损失图
axes[0, 0].plot(chatglm_6b_epochs, chatglm_6b_losses, marker='o', color='b', label='chatglm-6B')
axes[0, 0].set_title('chatglm-6B Evaluation Loss')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].grid(True, linestyle='--', alpha=0.7)
axes[0, 0].legend()

axes[0, 1].plot(qwen3_14b_epochs, qwen3_14b_losses, marker='s', color='r', label='Qwen3-14B')
axes[0, 1].set_title('Qwen3-14B Evaluation Loss')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Loss')
axes[0, 1].grid(True, linestyle='--', alpha=0.7)
axes[0, 1].legend()

axes[0, 2].plot(glm4_9b_epochs, glm4_9b_losses, marker='^', color='g', label='glm4-9B')
axes[0, 2].set_title('glm4-9B Evaluation Loss')
axes[0, 2].set_xlabel('Epoch')
axes[0, 2].set_ylabel('Loss')
axes[0, 2].grid(True, linestyle='--', alpha=0.7)
axes[0, 2].legend()

# 第二行：F1 图
axes[1, 0].plot(chatglm_6b_f1_epochs, chatglm_6b_f1, marker='o', color='b')
axes[1, 0].set_title('chatglm-6B F1')
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('F1')
axes[1, 0].grid(True, linestyle='--', alpha=0.7)

axes[1, 1].plot(qwen3_14b_f1_epochs, qwen3_14b_f1, marker='s', color='r')
axes[1, 1].set_title('Qwen3-14B F1')
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('F1')
axes[1, 1].grid(True, linestyle='--', alpha=0.7)

axes[1, 2].plot(glm4_9b_f1_epochs, glm4_9b_f1, marker='^', color='g')
axes[1, 2].set_title('GLM4-9B F1')
axes[1, 2].set_xlabel('Epoch')
axes[1, 2].set_ylabel('F1')
axes[1, 2].grid(True, linestyle='--', alpha=0.7)

# 自动布局
plt.tight_layout()
plt.show()