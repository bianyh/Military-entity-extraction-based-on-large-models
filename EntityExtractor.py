import os
import json
import torch
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from loguru import logger


class EntityExtractor:
    def __init__(self, base_model_path, lora_adapter_path, device="cuda"):
        """
        åˆå§‹åŒ–å®ä½“æå–å™¨
        :param base_model_path: åŸºç¡€æ¨¡å‹è·¯å¾„
        :param lora_adapter_path: LoRA é€‚é…å™¨ä¿å­˜è·¯å¾„
        :param device: ä½¿ç”¨çš„è®¾å¤‡ï¼Œé»˜è®¤ä¸º "cuda"ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è‡ªåŠ¨åˆ‡æ¢åˆ° "cpu"
        """
        self.base_model_path = base_model_path
        self.lora_adapter_path = lora_adapter_path
        self.device = device if torch.cuda.is_available() else "cpu"

        # é…ç½®æ—¥å¿—
        self.log_path = "./log"
        os.makedirs(self.log_path, exist_ok=True)
        logger.add(f"{self.log_path}/{os.path.basename(__file__)}.log", rotation="100 MB")

        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
        self.model = AutoModelForCausalLM.from_pretrained(
            self.base_model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16
        ).to(self.device)

        self.tokenizer = AutoTokenizer.from_pretrained(
            self.base_model_path,
            trust_remote_code=True
        )

        # åŠ è½½ LoRA é€‚é…å™¨åˆ°åŸºç¡€æ¨¡å‹ä¸Š
        self.model = PeftModel.from_pretrained(self.model, self.lora_adapter_path)
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

    def send_request(self, text: str, max_new_tokens: int = 64) -> list:
        """
        ä½¿ç”¨å¾®è°ƒåçš„ LoRA æ¨¡å‹è¿›è¡Œæ¨ç†
        :param text: è¾“å…¥æ–‡æœ¬
        :param max_new_tokens: æœ€å¤§ç”Ÿæˆæ–° token æ•°é‡ï¼Œé»˜è®¤ä¸º 256
        :return: æå–çš„å®ä½“åˆ—è¡¨
        """
        prompt = f"""You are an expert in military information extraction. Your job is to extract ** Military-related named entities ** from military-related English text, and classify each entity into one of the following 6 types:
        ["vehicle", "aircraft", "vessel", "weapon", "location", "other"]
        Below is a brief explanation of the 6 types:

        - Vehicle: A vehicle is a device or means of transportation designed for traveling on land. It can carry people or goods from one place to another, such as cars, buses, and bicycles.

        - Aircraft: An aircraft is a machine that can fly in the air. It generates thrust via engines and lift via wings to achieve flight, used for transporting passengers, cargo, or carrying out military missions.

        - Vessel: A vessel refers to a large - sized water - borne craft capable of navigating on water. It can be categorized into military vessels and civilian vessels, serving purposes such as maritime transportation, military operations, and scientific research.

        - Weapon: An offensive weapon is a device or instrument designed to attack targets and cause damage or destruction. Common examples include guns, missiles, and bombs, which play a crucial role in military operations.

        - Location: Location refers to the geographical position where something or somewhere is situated on the Earth's surface. It can be determined using geographical coordinates like latitude and longitude, and it's essential for describing the spatial distribution and connections of things.

        - Other: This category encompasses things or circumstances beyond the aforementioned concepts, exhibiting diversity and uncertainty, and requiring analysis based on specific contexts.

        Please follow these rules:
        1. Only extract entities that explicitly appear in the text and only classify them in the **6** types.
        2. Try to extract as little as possible that represents the entity, such as a codename. Only the most representative words can be extracted from the content that represents the same meaning in a sentence.
        3. You can only extract entities of military significance with obvious codenames. Non-military entities, such as brushes, or military entities that do not explicitly indicate the code name, such as generic references such as "soldier","rifles",etc. do not need to be extracted.
        4. Use the exact JSON array format.
        5. Do not explain or describe the output. Just return pure JSON.
        6. If you are sure that this text does not have a military entity that needs to be extracted, please return [].

        --- Examples ---

        Text: "The F-16 Fighting Falcon is an American fighter aircraft."
        Output:
        [
            {{"name":"F-16","label":"aircraft"}}
        ]

        Text: "The soldier is brushing his shoes with a brush"
        Output:
        []

        --- Now extract entities from the following text ---

        Text: "{text}"
        Output:
    """
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        try:
            with torch.no_grad():
                outputs = self.model.base_model.generate(
                    inputs.input_ids,
                    max_new_tokens=max_new_tokens,
                    do_sample=False
                )
        except torch.cuda.OutOfMemoryError:
            torch.cuda.empty_cache()
            with torch.no_grad():
                outputs = self.model.base_model.generate(
                    inputs.input_ids,
                    max_new_tokens=max_new_tokens,
                    do_sample=False
                )

        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        output_start_str = "Output:\n"
        output_start_index = response.rfind(output_start_str)
        if output_start_index != -1:
            response = response[output_start_index + len(output_start_str):].strip()
            logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

            # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
            try:
                # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
                start = response.find("[")
                end = response.find("]") + 1
                json_str = response[start:end]

                # Step 2: æ­£å¸¸è§£æ JSON
                entities = json.loads(json_str)
                ans = []
                for entity in entities:
                    if entity["name"] not in text:
                        continue
                    else:
                        ans.append(entity)
                return ans

            except Exception as e:
                logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
                return []
        else:
            logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

            # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
            try:
                # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
                start = response.find("[")
                end = response.find("]") + 1
                json_str = response[start:end]

                # Step 2: æ­£å¸¸è§£æ JSON
                entities = json.loads(json_str)
                ans = []
                for entity in entities:
                    if entity["name"] not in text:
                        continue
                    else:
                        ans.append(entity)
                return ans

            except Exception as e:
                logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
                return []

    def extract_entities_from_file(self, input_path: str, output_path: str):
        """
        ä»æ–‡ä»¶ä¸­æå–å®ä½“å¹¶ä¿å­˜ç»“æœ
        :param input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«æ–‡æœ¬æ•°æ®çš„ JSON æ–‡ä»¶
        :param output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¿å­˜æå–ç»“æœçš„ JSON æ–‡ä»¶
        """
        if not os.path.exists(input_path):
            logger.error(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_path}")
            return

        with open(input_path, "r", encoding="utf-8") as f:
            texts = json.load(f)

        results = {}

        for idx, item in tqdm(texts.items(), desc="ğŸ“ æ­£åœ¨æŠ½å–å®ä½“"):
            text = item["text"]
            try:
                logger.debug(f'å¤„ç†æ–‡æœ¬{text}')
                entities = self.inference_with_lora(text)
                results[idx] = entities
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
            except Exception as e:
                logger.error(f"[Error] ID: {idx}, Error: {e}")
                results[idx] = []

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        logger.info(f"\nâœ… å®ä½“æŠ½å–å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")

    def extract_entities_from_text(self, text: str) -> list:
        """
        ç›´æ¥ä¼ å…¥æ–‡æœ¬ï¼Œè¿”å›æå–çš„å®ä½“ JSON æ•°æ®
        :param text: è¾“å…¥æ–‡æœ¬
        :return: æå–çš„å®ä½“ JSON æ•°æ®
        """
        entities = self.inference_with_lora(text)
        return entities


# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    base_model_path = "./models/chatglm3-6b"  # åŸºç¡€æ¨¡å‹è·¯å¾„
    lora_adapter_path = "./output/sft_lora_chatglm3/lora_adapters"  # LoRA é€‚é…å™¨ä¿å­˜è·¯å¾„

    # åˆ›å»ºå®ä½“æå–å™¨å®ä¾‹
    extractor = EntityExtractor(base_model_path, lora_adapter_path)

    # è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_path = "./æ•°æ®é›†/sample_text_filter.json"
    output_path = "./output/entity_text_only_finetuned.json"

    # æ‰§è¡Œå®ä½“æå–
    extractor.extract_entities_from_file(input_path, output_path)

    # æµ‹è¯•ç›´æ¥ä¼ å…¥æ–‡æœ¬æå–å®ä½“
    sample_text = "The Ki-30, also known as the Type 97 Attack Bomber, along with the Type 98 Attack Bomber, was a main dive bomber of the Imperial Japanese Army."
    extracted_entities = extractor.extract_entities_from_text(sample_text)
    print(f"Extracted entities: {extracted_entities}")

# from flask import Flask, request, jsonify
# import os
# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
# import json
# import torch
# from transformers import AutoTokenizer, AutoModelForCausalLM
# from peft import PeftModel
# from loguru import logger

# # é…ç½®æ—¥å¿—
# log_path = "./log"
# os.makedirs(log_path, exist_ok=True)
# logger.add(f"{log_path}/app.log", rotation="100 MB")  # è‡ªåŠ¨åˆ†å‰²æ—¥å¿—æ–‡ä»¶

# # é…ç½®è·¯å¾„
# base_model_path = "./models/glm3-6b"  # åŸºç¡€æ¨¡å‹è·¯å¾„
# lora_adapter_path = "./output/sft_lora_glm3/checkpoint-2240"  # LoRA é€‚é…å™¨ä¿å­˜è·¯å¾„
# device = "cuda" if torch.cuda.is_available() else "cpu"

# # åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
# model = AutoModelForCausalLM.from_pretrained(
#     base_model_path,
#     trust_remote_code=True,
#     torch_dtype=torch.float16
# ).to(device)

# tokenizer = AutoTokenizer.from_pretrained(
#     base_model_path,
#     trust_remote_code=True
# )

# # åŠ è½½ LoRA é€‚é…å™¨åˆ°åŸºç¡€æ¨¡å‹ä¸Š
# model = PeftModel.from_pretrained(model, lora_adapter_path)
# model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

# app = Flask(__name__)


# # æ¨ç†ç¤ºä¾‹å‡½æ•°
# def inference_with_lora(text: str, max_new_tokens: int = 256) -> str:
#     """
#     ä½¿ç”¨å¾®è°ƒåçš„ LoRA æ¨¡å‹è¿›è¡Œæ¨ç†
#     """
#     prompt = f"""You are an expert in military information extraction. Your job is to extract ** Military-related named entities ** from military-related English text, and classify each entity into one of the following 6 types:
#         ["vehicle", "aircraft", "vessel", "weapon", "location", "other"]
#         Below is a brief explanation of the 6 types:

#         - Vehicle: A vehicle is a device or means of transportation designed for traveling on land. It can carry people or goods from one place to another, such as cars, buses, and bicycles.

#         - Aircraft: An aircraft is a machine that can fly in the air. It generates thrust via engines and lift via wings to achieve flight, used for transporting passengers, cargo, or carrying out military missions.

#         - Vessel: A vessel refers to a large - sized water - borne craft capable of navigating on water. It can be categorized into military vessels and civilian vessels, serving purposes such as maritime transportation, military operations, and scientific research.

#         - Weapon: An offensive weapon is a device or instrument designed to attack targets and cause damage or destruction. Common examples include guns, missiles, and bombs, which play a crucial role in military operations.

#         - Location: Location refers to the geographical position where something or somewhere is situated on the Earth's surface. It can be determined using geographical coordinates like latitude and longitude, and it's essential for describing the spatial distribution and connections of things.

#         - Other: This category encompasses things or circumstances beyond the aforementioned concepts, exhibiting diversity and uncertainty, and requiring analysis based on specific contexts.

#         Please follow these rules:
#         1. Only extract entities that explicitly appear in the text and only classify them in the **6** types.
#         2. Try to extract as little as possible that represents the entity, such as a codename. Only the most representative words can be extracted from the content that represents the same meaning in a sentence.
#         3. You can only extract entities of military significance with obvious codenames. Non-military entities, such as brushes, or military entities that do not explicitly indicate the code name, such as generic references such as "soldier","rifles",etc. do not need to be extracted.
#         4. Use the exact JSON array format.
#         5. Do not explain or describe the output. Just return pure JSON.
#         6. If you are sure that this text does not have a military entity that needs to be extracted, please return [].

#         --- Examples ---

#         Text: "The F-16 Fighting Falcon is an American fighter aircraft."
#         Output:
#         [
#             {{"name":"F-16","label":"aircraft"}}
#         ]

#         Text: "The soldier is brushing his shoes with a brush"
#         Output:
#         []

#         --- Now extract entities from the following text ---

#         Text: "{text}"
#         Output:
#     """
#     inputs = tokenizer(prompt, return_tensors="pt").to(device)
#     try:
#         with torch.no_grad():
#             outputs = model.base_model.generate(
#                 inputs.input_ids,
#                 max_new_tokens=max_new_tokens,
#                 do_sample=False
#             )
#     except torch.cuda.OutOfMemoryError:
#         torch.cuda.empty_cache()
#         with torch.no_grad():
#             outputs = model.base_model.generate(
#                 inputs.input_ids,
#                 max_new_tokens=max_new_tokens,
#                 do_sample=False
#             )

#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)
#     output_start_str = "Output:\n"
#     output_start_index = response.rfind(output_start_str)
#     if output_start_index != -1:
#         response = response[output_start_index + len(output_start_str):].strip()
#         logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

#         # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
#         try:
#             # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
#             start = response.find("[")
#             end = response.rfind("]") + 1
#             json_str = response[start:end]

#             # Step 2: æ­£å¸¸è§£æ JSON
#             entities = json.loads(json_str)
#             ans = []
#             for entity in entities:
#                 if entity["name"] not in text:
#                     continue
#                 else:
#                     ans.append(entity)
#             return ans

#         except Exception as e:
#             logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
#             return []
#     else:
#         logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

#         # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
#         try:
#             # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
#             start = response.find("[")
#             end = response.rfind("]") + 1
#             json_str = response[start:end]

#             # Step 2: æ­£å¸¸è§£æ JSON
#             entities = json.loads(json_str)
#             ans = []
#             for entity in entities:
#                 if entity["name"] not in text:
#                     continue
#                 else:
#                     ans.append(entity)
#             return ans

#         except Exception as e:
#             logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
#             return []


# @app.route('/extract_entities', methods=['POST'])
# def extract_entities():
#     try:
#         data = request.get_json()
#         text = data.get('text')
#         if not text:
#             return jsonify({"error": "No text provided"}), 400

#         entities = inference_with_lora(text)
#         return jsonify(entities), 200

#     except Exception as e:
#         logger.error(f"Error processing request: {e}")
#         return jsonify({"error": str(e)}), 500


# if __name__ == '__main__':
#     app.run(host='0.0.0.0', port=5000)

# import json
# import requests
# import os
#
# # é…ç½®æ–‡ä»¶è·¯å¾„
# input_path = "./æ•°æ®é›†/sample_text_filter.json"  # è¾“å…¥æ•°æ®é›†æ–‡ä»¶
# output_path = "./output/results.json"  # è¾“å‡ºç»“æœæ–‡ä»¶
# api_url = "http://localhost:5000/extract_entities"  # Flask åç«¯æ¥å£åœ°å€
#
# # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
# os.makedirs(os.path.dirname(output_path), exist_ok=True)
#
# # è¯»å–æ•°æ®é›†
# if not os.path.exists(input_path):
#     print(f"æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_path}")
#     exit(1)
#
# with open(input_path, "r", encoding="utf-8") as f:
#     texts = json.load(f)
#
# # åˆå§‹åŒ–ç»“æœå­—å…¸
# results = {}
#
# # éå†æ•°æ®é›†å¹¶å‘é€è¯·æ±‚
# for idx, item in texts.items():
#     text = item["text"]
#     print(f"å¤„ç† ID: {idx}, æ–‡æœ¬: {text}")
#
#     # å‘é€ POST è¯·æ±‚åˆ° Flask åç«¯
#     response = requests.post(api_url, json={"text": text})
#
#     # æ£€æŸ¥å“åº”çŠ¶æ€
#     if response.status_code == 200:
#         entities = response.json()
#         results[idx] = entities
#         print(f"æˆåŠŸè·å–ç»“æœï¼š{entities}")
#     else:
#         print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
#         results[idx] = []
#
# # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
# with open(output_path, "w", encoding="utf-8") as f:
#     json.dump(results, f, indent=2, ensure_ascii=False)
#
# print(f"æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")