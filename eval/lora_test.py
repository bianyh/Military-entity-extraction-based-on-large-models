import os
import json
import torch
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from loguru import logger


# æ¨ç†ç¤ºä¾‹å‡½æ•°
def inference_with_lora(text: str, max_new_tokens: int = 256) -> str:
    """
    ä½¿ç”¨å¾®è°ƒåçš„ LoRA æ¨¡å‹è¿›è¡Œæ¨ç†
    """
    prompt = f"""You are an expert in military information extraction. Your job is to extract ** Military-related named entities ** from military-related English text, and classify each entity into one of the following 6 types:
        ["vehicle", "aircraft", "vessel", "weapon", "location", "other"]
        Below is a brief explanation of the 6 types:

        - Vehicle: A vehicle is a device or means of transportation designed for traveling on land. It can carry people or goods from one place to another, such as cars, buses, and bicycles.

        - Aircraft: An aircraft is a machine that can fly in the air. It generates thrust via engines and lift via wings to achieve flight, used for transporting passengers, cargo, or carrying out military missions.

        - Vessel: A vessel refers to a large - sized water - borne craft capable of navigating on water. It can be categorized into military vessels and civilian vessels, serving purposes such as maritime transportation, military operations, and scientific research.

        - Weapon: An offensive weapon is a device or instrument designed to attack targets and cause damage or destruction. Common examples include guns, missiles, and bombs, which play a crucial role in military operations.

        - Location: Location refers to the geographical position where something or somewhere is situated on the Earth's surface. It can be determined using geographical coordinates like latitude and longitude, and it's essential for describing the spatial distribution and connections of things.

        - Other: This category encompasses things or circumstances beyond the aforementioned concepts, exhibiting diversity and uncertainty, and requiring analysis based on specific contexts.

        Please follow these rules:
        1. Only extract entities that explicitly appear in the text and only classify them in the **6** types.
        2. Try to extract as little as possible that represents the entity, such as a codename. Only the most representative words can be extracted from the content that represents the same meaning in a sentence.
        3. You can only extract entities of military significance with obvious codenames. Non-military entities, such as brushes, or military entities that do not explicitly indicate the code name, such as generic references such as "soldier","rifles",etc. do not need to be extracted.
        4. Use the exact JSON array format.
        5. Do not explain or describe the output. Just return pure JSON.
        6. If you are sure that this text does not have a military entity that needs to be extracted, please return [].

        --- Examples ---

        Text: "The F-16 Fighting Falcon is an American fighter aircraft."
        Output:
        [
            {{"name":"F-16","label":"aircraft"}}
        ]

        Text: "The soldier is brushing his shoes with a brush"
        Output:
        []

        --- Now extract entities from the following text ---

        Text: "{text}"
        Output:
"""
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    try:
        with torch.no_grad():
            outputs = model.base_model.generate(
                inputs.input_ids,
                max_new_tokens=max_new_tokens,
                do_sample=False
            )
    except torch.cuda.OutOfMemoryError:
        torch.cuda.empty_cache()
        with torch.no_grad():
            outputs = model.base_model.generate(
                inputs.input_ids,
                max_new_tokens=max_new_tokens,
                do_sample=False
            )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    output_start_str = "Output:\n"
    output_start_index = response.rfind(output_start_str)
    if output_start_index != -1:
        response = response[output_start_index + len(output_start_str):].strip()
        logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

        # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
        try:
            # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
            start = response.find("[")
            end = response.find("]") + 1
            json_str = response[start:end]

            # Step 2: æ­£å¸¸è§£æ JSON
            entities = json.loads(json_str)
            ans = []
            for entity in entities:
                if entity["name"] not in text:
                    continue
                else:
                    ans.append(entity)
            return ans
            return entities

        except Exception as e:
            logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
            return []
    else:
        logger.debug(f"\nğŸ” [DEBUG] æ¨¡å‹åŸå§‹è¾“å‡º:\n{response.strip()}\n")

        # ====== å°è¯•æå– JSON éƒ¨åˆ† ======
        try:
            # Step 1: ä¼˜å…ˆæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„ï¼ˆä» [ å¼€å§‹åˆ° ] ç»“æŸï¼‰
            start = response.find("[")
            end = response.find("]") + 1
            json_str = response[start:end]

            # Step 2: æ­£å¸¸è§£æ JSON
            entities = json.loads(json_str)
            return entities

        except Exception as e:
            logger.warning(f"âš ï¸ json.loads å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
            return []


# ========== ä¸»ç¨‹åº ==========
def main():
    input_path = "./æ•°æ®é›†/val_text.json"
    # æ„å»ºè¾“å‡ºè·¯å¾„
    output_dir = f"./output/{model_name}/{weitiao_banben}"
    output_path = os.path.join(output_dir, "result.json")  # å‡è®¾æœ€ç»ˆè¾“å‡ºæ–‡ä»¶åæ˜¯ result.json

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        logger.error(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_path}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_dir, exist_ok=True)
    logger.info(f"âœ… è¾“å‡ºç›®å½•å·²å‡†å¤‡å°±ç»ªï¼š{output_dir}")

    with open(input_path, "r", encoding="utf-8") as f:
        texts = json.load(f)

    results = {}

    for idx, item in tqdm(texts.items(), desc="ğŸ“ æ­£åœ¨æŠ½å–å®ä½“"):
        text = item["text"]
        try:
            logger.debug(f'å¤„ç†æ–‡æœ¬{text}')
            entities = inference_with_lora(text)
            results[idx] = entities
        except Exception as e:
            logger.error(f"[Error] ID: {idx}, Error: {e}")
            results[idx] = []

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logger.info(f"\nâœ… å®ä½“æŠ½å–å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")


# é…ç½®æ—¥å¿—
log_path = "./log"
os.makedirs(log_path, exist_ok=True)
logger.add(f"{log_path}/{os.path.basename(__file__)}.log", rotation="100 MB")  # è‡ªåŠ¨åˆ†å‰²æ—¥å¿—æ–‡ä»¶

model_name = "glm4-9b"
nums = [280, 560, 840, 1120, 1400, 1680, 1960, 2240, 2520, 2800]
for i in nums:
    try:
        weitiao_banben = f"checkpoint-{i}"

        # é…ç½®è·¯å¾„
        base_model_path = f"./models/{model_name}"  # åŸºç¡€æ¨¡å‹è·¯å¾„
        lora_adapter_path = f"./output/sft_lora_glm4/{weitiao_banben}"  # LoRA é€‚é…å™¨ä¿å­˜è·¯å¾„
        device = "cuda" if torch.cuda.is_available() else "cpu"

        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
        model = AutoModelForCausalLM.from_pretrained(
            base_model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16
        ).to(device)

        tokenizer = AutoTokenizer.from_pretrained(
            base_model_path,
            trust_remote_code=True
        )

        # åŠ è½½ LoRA é€‚é…å™¨åˆ°åŸºç¡€æ¨¡å‹ä¸Š
        model = PeftModel.from_pretrained(model, lora_adapter_path)
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        if __name__ == "__main__":
            main()
    except Exception as e:
        del model
        del tokenizer
        torch.cuda.empty_cache()

        weitiao_banben = f"checkpoint-{i}"

        # é…ç½®è·¯å¾„
        base_model_path = f"./models/{model_name}"  # åŸºç¡€æ¨¡å‹è·¯å¾„
        lora_adapter_path = f"./output/sft_lora_glm4/{weitiao_banben}"  # LoRA é€‚é…å™¨ä¿å­˜è·¯å¾„
        device = "cuda" if torch.cuda.is_available() else "cpu"

        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
        model = AutoModelForCausalLM.from_pretrained(
            base_model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16
        ).to(device)

        tokenizer = AutoTokenizer.from_pretrained(
            base_model_path,
            trust_remote_code=True
        )

        # åŠ è½½ LoRA é€‚é…å™¨åˆ°åŸºç¡€æ¨¡å‹ä¸Š
        model = PeftModel.from_pretrained(model, lora_adapter_path)
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        if __name__ == "__main__":
            main()


